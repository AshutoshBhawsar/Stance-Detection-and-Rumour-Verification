{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_taska.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KELrmE23QnU6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import numpy  as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "from sklearn.metrics                  import classification_report\n",
        "from sklearn.feature_extraction.text  import TfidfVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_path = '/content/drive/MyDrive/NLP/rumoureval2019/rumoureval-2019-training-data'\n",
        "test_data_path     = '/content/drive/MyDrive/NLP/rumoureval2019/rumoureval-2019-test-data'\n",
        "\n",
        "twitter_trainingDev_data_path = training_data_path + '/twitter-english'\n",
        "twitter_test_data_path        = test_data_path + '/twitter-en-test-data'\n",
        "\n",
        "path_train_key = '/content/drive/MyDrive/NLP/rumoureval2019/rumoureval-2019-training-data/train-key.json'\n",
        "path_dev_key   = '/content/drive/MyDrive/NLP/rumoureval2019/rumoureval-2019-training-data/dev-key.json'\n",
        "path_test_key  = '/content/drive/MyDrive/NLP/rumoureval2019/final-eval-key.json'\n",
        "\n",
        "reddit_train_data_path  =  training_data_path + '/reddit-training-data'\n",
        "reddit_dev_data_path    =  training_data_path + '/reddit-dev-data'\n",
        "reddit_test_data_path   =  test_data_path     + '/reddit-test-data'"
      ],
      "metadata": {
        "id": "S8N6ZEK_QwE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_key_df = pd.read_json(path_train_key)\n",
        "dev_key_df = pd.read_json(path_dev_key)\n",
        "test_key_df = pd.read_json(path_test_key)"
      ],
      "metadata": {
        "id": "mXtXVU81RCPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processRedditKeyDataFrame(key_df, datasetType):\n",
        "    key_taska_df = pd.DataFrame(key_df['subtaskaenglish'].dropna())\n",
        "    \n",
        "    key_taska_df = key_taska_df.reset_index()\n",
        "    key_taska_df = key_taska_df.rename(columns={'index': 'id', 'subtaskaenglish': 'label'})\n",
        "    \n",
        "    if datasetType   ==  'train':\n",
        "        reddit_key_tasks_df = key_taska_df[4519:] \n",
        "    elif datasetType ==  'dev':\n",
        "        reddit_key_tasks_df = key_taska_df[1049:] \n",
        "    elif datasetType ==  'test':\n",
        "        reddit_key_tasks_df =  key_taska_df[1066:] \n",
        "    return reddit_key_tasks_df"
      ],
      "metadata": {
        "id": "MhjugMBZRPFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_key_df = processRedditKeyDataFrame(train_key_df, 'train')\n",
        "reddit_dev_key_df   = processRedditKeyDataFrame(dev_key_df, 'dev')\n",
        "reddit_test_key_df  = processRedditKeyDataFrame(test_key_df, 'test')"
      ],
      "metadata": {
        "id": "b_spczYkRcV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processRedditSourcePosts(reddit_dataset_path):\n",
        "    reddit_dirs = next(os.walk(reddit_dataset_path))[1] \n",
        "    reddit_dirs_sorted = sorted(reddit_dirs)\n",
        "    \n",
        "    reddit_src_dirs  = []\n",
        "    reddit_src_posts = []\n",
        "    \n",
        "    for directory in reddit_dirs_sorted:\n",
        "        reddit_src_path = reddit_dataset_path + '/' + directory + '/source-tweet'\n",
        "        reddit_src_dirs.append(next(os.walk(reddit_src_path))[2])\n",
        "    \n",
        "    src_reddit_files = []\n",
        "    for sdirs in reddit_src_dirs:\n",
        "        for i in sdirs:\n",
        "            src_reddit_files.append(i)\n",
        "    src_reddit_files_sorted = sorted(src_reddit_files)\n",
        "    \n",
        "    for file in src_reddit_files_sorted:\n",
        "        paths = reddit_dataset_path + '/' + file.split('.')[0] + '/source-tweet' + '/' + file \n",
        "        reddit_post_dict = {}\n",
        "        \n",
        "       \n",
        "        with open(paths) as f:\n",
        "            for line in f:\n",
        "                src = json.loads(line)\n",
        "                text = src['data']['children'][0]['data']['title']\n",
        "                rid = src['data']['children'][0]['data']['id']\n",
        "                \n",
        "                reddit_post_dict['text'] = text  \n",
        "                reddit_post_dict['id'] = rid     \n",
        "                \n",
        "           \n",
        "                reddit_post_dict['inre'] = 'None'\n",
        "                reddit_src_posts.append(reddit_post_dict)\n",
        "\n",
        "    return reddit_dirs_sorted, reddit_src_posts"
      ],
      "metadata": {
        "id": "aJVe_QOsRfCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_dirs_sorted , reddit_train_src_posts = processRedditSourcePosts(reddit_train_data_path)\n",
        "reddit_train_src_posts_df = pd.DataFrame(reddit_train_src_posts)\n",
        "\n",
        "reddit_dev_dirs_sorted , reddit_dev_src_posts = processRedditSourcePosts(reddit_dev_data_path)\n",
        "reddit_dev_src_posts_df = pd.DataFrame(reddit_dev_src_posts)\n",
        "\n",
        "reddit_test_dirs_sorted , reddit_test_src_posts = processRedditSourcePosts(reddit_test_data_path)\n",
        "reddit_test_src_posts_df = pd.DataFrame(reddit_test_src_posts)"
      ],
      "metadata": {
        "id": "56IH4cKwRjUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_src_posts_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "4D4ZGBqJRpbm",
        "outputId": "372b92d4-45bb-422b-d854-af6493a4613f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4be3828b-c9fa-4c31-b08d-c795d1af7b26\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>inre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Even ants won't eat aspartame!</td>\n",
              "      <td>18dmb4</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Cancer is a fungus\" - this idea from the 60s ...</td>\n",
              "      <td>1hzz6y</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>repost from TIL : 'financial guru' Robert Kiyo...</td>\n",
              "      <td>1i8cy7</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is it true that if you are not a member of the...</td>\n",
              "      <td>1i8ljs</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How much truth is there in the statement that ...</td>\n",
              "      <td>22o24j</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Debunk This: Microwaves are bad because microw...</td>\n",
              "      <td>249p6c</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Debunk this: Nicotine isn't really bad for you...</td>\n",
              "      <td>25bvmb</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Would Labour win if young people voted?</td>\n",
              "      <td>46uw4y</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>California To Allow Illegal Immigrants To Vote...</td>\n",
              "      <td>46yxoy</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>'Queen backs Brexit' - The Sun front page tomo...</td>\n",
              "      <td>49l01s</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[Debunk this]Carl Sagan settled an argument be...</td>\n",
              "      <td>4c7iec</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>In an episode of a Tv show released recently, ...</td>\n",
              "      <td>5938df</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>California driver licenses given to 800,000 un...</td>\n",
              "      <td>5l23au</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Debunk this: The '97% consensus' of scientists...</td>\n",
              "      <td>5mkmg1</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Donald Trump's travel expenses in 10 weeks cos...</td>\n",
              "      <td>63uefi</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Is it true that when you shave hair on a certa...</td>\n",
              "      <td>644j1f</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>People of Reddit! Game of Thrones Bosses Confi...</td>\n",
              "      <td>6a4cji</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>DEBUNK THIS: We could not return to earth afte...</td>\n",
              "      <td>6o9ozz</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Debunk This: \"throughout human history, while ...</td>\n",
              "      <td>6rimvf</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What exactly is happening when you crack your ...</td>\n",
              "      <td>78sxy7</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Did Trump call Republicans “the dumbest group ...</td>\n",
              "      <td>7jkthr</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Is it true there has never been a war between ...</td>\n",
              "      <td>7p7cq</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Like in movies, Is it true when police are loc...</td>\n",
              "      <td>7z11oi</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Brits of Reddit, is it true that when you're d...</td>\n",
              "      <td>8d6h5t</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Is it true that we have as a species, twice as...</td>\n",
              "      <td>8efswb</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[Serious] Is it true that 85% of people can on...</td>\n",
              "      <td>8gp0d7</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Did Eric Schneiderman Help NXIVM Sell Child Se...</td>\n",
              "      <td>8i274x</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Debunk this: The direction you sleep matters</td>\n",
              "      <td>8n9173</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Is it true police officers must hit a quota at...</td>\n",
              "      <td>8unvgg</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Jon Sopel: Bizarre. @realDonaldTrump says he c...</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4be3828b-c9fa-4c31-b08d-c795d1af7b26')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4be3828b-c9fa-4c31-b08d-c795d1af7b26 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4be3828b-c9fa-4c31-b08d-c795d1af7b26');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 text      id  inre\n",
              "0                      Even ants won't eat aspartame!  18dmb4  None\n",
              "1   \"Cancer is a fungus\" - this idea from the 60s ...  1hzz6y  None\n",
              "2   repost from TIL : 'financial guru' Robert Kiyo...  1i8cy7  None\n",
              "3   Is it true that if you are not a member of the...  1i8ljs  None\n",
              "4   How much truth is there in the statement that ...  22o24j  None\n",
              "5   Debunk This: Microwaves are bad because microw...  249p6c  None\n",
              "6   Debunk this: Nicotine isn't really bad for you...  25bvmb  None\n",
              "7             Would Labour win if young people voted?  46uw4y  None\n",
              "8   California To Allow Illegal Immigrants To Vote...  46yxoy  None\n",
              "9   'Queen backs Brexit' - The Sun front page tomo...  49l01s  None\n",
              "10  [Debunk this]Carl Sagan settled an argument be...  4c7iec  None\n",
              "11  In an episode of a Tv show released recently, ...  5938df  None\n",
              "12  California driver licenses given to 800,000 un...  5l23au  None\n",
              "13  Debunk this: The '97% consensus' of scientists...  5mkmg1  None\n",
              "14  Donald Trump's travel expenses in 10 weeks cos...  63uefi  None\n",
              "15  Is it true that when you shave hair on a certa...  644j1f  None\n",
              "16  People of Reddit! Game of Thrones Bosses Confi...  6a4cji  None\n",
              "17  DEBUNK THIS: We could not return to earth afte...  6o9ozz  None\n",
              "18  Debunk This: \"throughout human history, while ...  6rimvf  None\n",
              "19  What exactly is happening when you crack your ...  78sxy7  None\n",
              "20  Did Trump call Republicans “the dumbest group ...  7jkthr  None\n",
              "21  Is it true there has never been a war between ...   7p7cq  None\n",
              "22  Like in movies, Is it true when police are loc...  7z11oi  None\n",
              "23  Brits of Reddit, is it true that when you're d...  8d6h5t  None\n",
              "24  Is it true that we have as a species, twice as...  8efswb  None\n",
              "25  [Serious] Is it true that 85% of people can on...  8gp0d7  None\n",
              "26  Did Eric Schneiderman Help NXIVM Sell Child Se...  8i274x  None\n",
              "27       Debunk this: The direction you sleep matters  8n9173  None\n",
              "28  Is it true police officers must hit a quota at...  8unvgg  None\n",
              "29  Jon Sopel: Bizarre. @realDonaldTrump says he c...  8yktu5  None"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processRedditReplyPosts(reddit_dataset_path, reddit_dirs_sorted):\n",
        "    replies_files = []\n",
        "    reddit_replies = []\n",
        "\n",
        "    for directory in reddit_dirs_sorted:\n",
        "        reddit_src_path = reddit_dataset_path + '/' + directory + '/replies' #Accessing the replies directory\n",
        "        replies_files.append(next(os.walk(reddit_src_path))[2])\n",
        "        \n",
        "        for i in (next(os.walk(reddit_src_path))[2]):\n",
        "            paths = reddit_dataset_path + '/' + directory + '/replies' + '/' + i #Accesing each reply file\n",
        "            reddit_post_dict = {}\n",
        "            with open(paths) as f:\n",
        "                for line in f:\n",
        "                    src = json.loads(line)\n",
        "                    rid = src['data']['id']\n",
        "                    inre = src['data']['parent_id']\n",
        "                    \n",
        "                    '''A few replies do not have any text data. This was because some of the replies were \n",
        "                    deleted but they were kept as is in the rumourEval data'''\n",
        "                    \n",
        "                    if 'body' in src['data']: \n",
        "                        text = src['data']['body']\n",
        "\n",
        "                    reddit_post_dict['text'] = text               \n",
        "                    reddit_post_dict['id'] = rid                  \n",
        "                    reddit_post_dict['inre'] = inre.split('_')[1] \n",
        "                    reddit_post_dict['source'] = directory       \n",
        "                    reddit_replies.append(reddit_post_dict)\n",
        "                    \n",
        "   \n",
        "  \n",
        "    return reddit_replies"
      ],
      "metadata": {
        "id": "W0JM-vYVR-Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_replies    = processRedditReplyPosts(reddit_train_data_path, reddit_train_dirs_sorted)\n",
        "reddit_train_replies_df = pd.DataFrame(reddit_train_replies)\n",
        "\n",
        "reddit_dev_replies    = processRedditReplyPosts(reddit_dev_data_path, reddit_dev_dirs_sorted)\n",
        "reddit_dev_replies_df = pd.DataFrame(reddit_dev_replies)\n",
        "\n",
        "reddit_test_replies    = processRedditReplyPosts(reddit_test_data_path, reddit_test_dirs_sorted)\n",
        "reddit_test_replies_df = pd.DataFrame(reddit_test_replies)"
      ],
      "metadata": {
        "id": "7-djqVQdSM3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_replies_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cJjf20GtSPks",
        "outputId": "b9eaf0b8-4785-4f90-bfed-18b32a93c157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d862ff6b-1ff6-4beb-b3fa-d6eea715e261\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>inre</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Snopes has the basics:  \\nwww.snopes.com/humor...</td>\n",
              "      <td>c8duhn4</td>\n",
              "      <td>18dmb4</td>\n",
              "      <td>18dmb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wikipedia would be a good start, I think.  \\nh...</td>\n",
              "      <td>c8du4n0</td>\n",
              "      <td>18dmb4</td>\n",
              "      <td>18dmb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Depends on how ants metabolize sugars, I suppo...</td>\n",
              "      <td>c8e0wj3</td>\n",
              "      <td>c8e0jxh</td>\n",
              "      <td>18dmb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the tag line in the bottom right corne...</td>\n",
              "      <td>c8e2l5p</td>\n",
              "      <td>c8e0t4f</td>\n",
              "      <td>18dmb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TIL: Aspartame contains 10 calories per teaspo...</td>\n",
              "      <td>c8e0ls2</td>\n",
              "      <td>c8duzth</td>\n",
              "      <td>18dmb4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>&amp;gt; That isn't disputed, it's that he came to...</td>\n",
              "      <td>e2bmzf2</td>\n",
              "      <td>e2bmcct</td>\n",
              "      <td>8yktu5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>In the press conference earlier today he said ...</td>\n",
              "      <td>e2bos7p</td>\n",
              "      <td>e2bo412</td>\n",
              "      <td>8yktu5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>665</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>e2btp0f</td>\n",
              "      <td>e2bta92</td>\n",
              "      <td>8yktu5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>666</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>e2bxvw0</td>\n",
              "      <td>e2bxjzw</td>\n",
              "      <td>8yktu5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "      <td>e2c1n3o</td>\n",
              "      <td>e2bv4kg</td>\n",
              "      <td>8yktu5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>668 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d862ff6b-1ff6-4beb-b3fa-d6eea715e261')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d862ff6b-1ff6-4beb-b3fa-d6eea715e261 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d862ff6b-1ff6-4beb-b3fa-d6eea715e261');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                  text  ...  source\n",
              "0    Snopes has the basics:  \\nwww.snopes.com/humor...  ...  18dmb4\n",
              "1    Wikipedia would be a good start, I think.  \\nh...  ...  18dmb4\n",
              "2    Depends on how ants metabolize sugars, I suppo...  ...  18dmb4\n",
              "3    What is the tag line in the bottom right corne...  ...  18dmb4\n",
              "4    TIL: Aspartame contains 10 calories per teaspo...  ...  18dmb4\n",
              "..                                                 ...  ...     ...\n",
              "663  &gt; That isn't disputed, it's that he came to...  ...  8yktu5\n",
              "664  In the press conference earlier today he said ...  ...  8yktu5\n",
              "665                                          [deleted]  ...  8yktu5\n",
              "666                                          [deleted]  ...  8yktu5\n",
              "667  Yeah seems like he is either blatantly lying o...  ...  8yktu5\n",
              "\n",
              "[668 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def redditCleanDf(src_posts_df, replies_df):\n",
        "    reddit_data = [src_posts_df, replies_df]\n",
        "\n",
        "    reddit_data = pd.concat(reddit_data)\n",
        "\n",
        "    reddit_data['id'] = reddit_data.id.astype(str)\n",
        "    reddit_data['inre'] = reddit_data.inre.astype(str)\n",
        "    \n",
        "    reddit_clean_data = pd.DataFrame(reddit_data)\n",
        "    \n",
        "    reddit_clean_data.id = reddit_clean_data.id.str.strip()    \n",
        "    reddit_clean_data.inre = reddit_clean_data.inre.str.strip() \n",
        "    return reddit_clean_data"
      ],
      "metadata": {
        "id": "n5TKR7xiS6_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "reddit_clean_train_df = redditCleanDf(reddit_train_src_posts_df, reddit_train_replies_df)\n",
        "reddit_clean_dev_df   = redditCleanDf(reddit_dev_src_posts_df, reddit_dev_replies_df)\n",
        "reddit_clean_test_df  = redditCleanDf(reddit_test_src_posts_df, reddit_test_replies_df)\n",
        "\n",
        "\n",
        "reddit_train_withKeys_df = pd.merge(reddit_clean_train_df, reddit_train_key_df, how = 'inner', on = \"id\", )\n",
        "reddit_dev_withKeys_df   = pd.merge(reddit_clean_dev_df, reddit_dev_key_df, how = 'inner', on = \"id\", )\n",
        "reddit_test_withKeys_df  = pd.merge(reddit_clean_test_df, reddit_test_key_df, how = 'inner', on = \"id\", )"
      ],
      "metadata": {
        "id": "g46P13f_TBtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetchRedditDataset(reddit_withKeys_df):\n",
        "    \n",
        "    reddit_df = reddit_withKeys_df[['id', 'text']].copy()\n",
        "    \n",
        "    reddit_df_new = reddit_df.rename(columns={'id': 'inre', 'text': 'inreText'})\n",
        "    reddit_df_new1 = reddit_df.rename(columns={'id': 'source', 'text': 'sourceText'})\n",
        "    \n",
        "    reddit_dataset = pd.merge(reddit_withKeys_df, reddit_df_new, how = 'left', on = \"inre\", )\n",
        "    reddit_dataset1 = pd.merge(reddit_withKeys_df, reddit_df_new1, how = 'left', on = \"source\", )\n",
        "    \n",
        "    return reddit_dataset, reddit_dataset1"
      ],
      "metadata": {
        "id": "d0qFCmzmTEUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_train_dataset_inre, reddit_train_dataset_src = fetchRedditDataset(reddit_train_withKeys_df)\n",
        "reddit_dev_dataset_inre, reddit_dev_dataset_src= fetchRedditDataset(reddit_dev_withKeys_df)\n",
        "reddit_test_dataset_inre, reddit_test_dataset_src = fetchRedditDataset(reddit_test_withKeys_df)\n",
        "\n",
        "reddit_train_dataset_src = pd.merge(reddit_train_dataset_inre, reddit_train_dataset_src, how = 'inner', on = \"id\",)\n",
        "reddit_dev_dataset_src = pd.merge(reddit_dev_dataset_inre, reddit_dev_dataset_src, how = 'inner', on = \"id\",)\n",
        "reddit_test_dataset_src = pd.merge(reddit_test_dataset_inre, reddit_test_dataset_src, how = 'inner', on = \"id\",)\n",
        "\n",
        "reddit_new_train_data_df = reddit_train_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()\n",
        "reddit_new_dev_data_df = reddit_dev_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()\n",
        "reddit_new_test_data_df = reddit_test_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()"
      ],
      "metadata": {
        "id": "QH9TzbWwTHfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeRedundantData(reddit_df):\n",
        "    for i in range(0,len(reddit_df)):\n",
        "        if reddit_df['inre_x'][i] == reddit_df['source_x'][i]:\n",
        "            reddit_df['sourceText'][i] = np.nan\n",
        "    return reddit_df"
      ],
      "metadata": {
        "id": "ub_ZvnQKTKs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_new_train_data_df = removeRedundantData(reddit_new_train_data_df)\n",
        "reddit_new_dev_data_df   = removeRedundantData(reddit_new_dev_data_df)\n",
        "reddit_new_test_data_df  = removeRedundantData(reddit_new_test_data_df)"
      ],
      "metadata": {
        "id": "BL54KhFZTNRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_new_train_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/RedditTrainDataSrc.csv', encoding='utf-8', index=False)\n",
        "reddit_new_dev_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/RedditDevDataSrc.csv', encoding='utf-8', index=False)\n",
        "reddit_new_test_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/RedditTestDataSrc.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "ZEtzKYGVTPNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/RedditDevDataSrc.csv')"
      ],
      "metadata": {
        "id": "CrZLzE8BTZy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Igjg1_waTgMe",
        "outputId": "667bc1b7-2877-4762-ad2d-800d530e0d0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b023f3d-272b-4e23-be33-03fc8156c135\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_x</th>\n",
              "      <th>id</th>\n",
              "      <th>inre_x</th>\n",
              "      <th>source_x</th>\n",
              "      <th>label_x</th>\n",
              "      <th>inreText</th>\n",
              "      <th>sourceText</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fukushima spewing equivalent of 112 Hiroshima-...</td>\n",
              "      <td>1jvbd8</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>deny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[serious] Man and dinosaurs lived at the same ...</td>\n",
              "      <td>31xv6u</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>support</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Debunk this: Fluoride declared neurotoxin, cau...</td>\n",
              "      <td>4dfdvo</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>query</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is it true that if you have your phone on char...</td>\n",
              "      <td>5qzxep</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>query</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Debunk this: Mt. Etna has already put out more...</td>\n",
              "      <td>66yxyf</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>query</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Remember the fluorides in our water replaces w...</td>\n",
              "      <td>e3bk3q8</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>We evolved as omnivores, but I do agree with y...</td>\n",
              "      <td>e3ay5vh</td>\n",
              "      <td>e3ak72f</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Oh they put iodine in salt here in Latin Ameri...</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>&amp;gt; 7 drops in about a double shot of cold wa...</td>\n",
              "      <td>e3c5joo</td>\n",
              "      <td>e3bqum8</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>I do about 7 drops in about a double shot of c...</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>The book The Iodine Crisis is really good and ...</td>\n",
              "      <td>e3bq78h</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>support</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>Iodine definitely degrades from iodized salt.</td>\n",
              "      <td>e3b6bd7</td>\n",
              "      <td>e3b3p2h</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Edit: we've found this comment to likely be te...</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>436 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b023f3d-272b-4e23-be33-03fc8156c135')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b023f3d-272b-4e23-be33-03fc8156c135 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b023f3d-272b-4e23-be33-03fc8156c135');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text_x  ...                                         sourceText\n",
              "0    Fukushima spewing equivalent of 112 Hiroshima-...  ...                                                NaN\n",
              "1    [serious] Man and dinosaurs lived at the same ...  ...                                                NaN\n",
              "2    Debunk this: Fluoride declared neurotoxin, cau...  ...                                                NaN\n",
              "3    Is it true that if you have your phone on char...  ...                                                NaN\n",
              "4    Debunk this: Mt. Etna has already put out more...  ...                                                NaN\n",
              "..                                                 ...  ...                                                ...\n",
              "431  Remember the fluorides in our water replaces w...  ...                                                NaN\n",
              "432  We evolved as omnivores, but I do agree with y...  ...  Iodine increases IQ and is an essential part o...\n",
              "433  &gt; 7 drops in about a double shot of cold wa...  ...  Iodine increases IQ and is an essential part o...\n",
              "434  The book The Iodine Crisis is really good and ...  ...                                                NaN\n",
              "435      Iodine definitely degrades from iodized salt.  ...  Iodine increases IQ and is an essential part o...\n",
              "\n",
              "[436 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_key_df = pd.read_json(path_train_key)\n",
        "dev_key_df = pd.read_json(path_dev_key)\n",
        "test_key_df = pd.read_json(path_test_key)"
      ],
      "metadata": {
        "id": "_jZfLtEkTw6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processTwitterKeyDataFrame(key_df, datasetType):\n",
        "    key_taska_df = pd.DataFrame(key_df['subtaskaenglish'].dropna())\n",
        "    \n",
        "\n",
        "    key_taska_df = key_taska_df.reset_index()\n",
        "    key_taska_df = key_taska_df.rename(columns={'index': 'id', 'subtaskaenglish': 'label'})\n",
        "    \n",
        "    if datasetType == 'train':\n",
        "        twitter_key_tasks_df = key_taska_df[0:4519] \n",
        "    elif datasetType == 'dev':\n",
        "        twitter_key_tasks_df = key_taska_df[0:1049] \n",
        "    elif datasetType == 'test':\n",
        "        twitter_key_tasks_df =  key_taska_df[0:1066]\n",
        "    return twitter_key_tasks_df"
      ],
      "metadata": {
        "id": "yCxtTlbDT9Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_train_key_df = processTwitterKeyDataFrame(train_key_df, 'train')\n",
        "twitter_dev_key_df = processTwitterKeyDataFrame(dev_key_df, 'dev')\n",
        "twitter_test_key_df = processTwitterKeyDataFrame(test_key_df, 'test')"
      ],
      "metadata": {
        "id": "A_2J6bSJT_fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_trainingDev_data_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wqmnzk4SW3Ub",
        "outputId": "9525c89f-3fd8-42db-e9f5-ae59e99dd960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/NLP/rumoureval2019/rumoureval-2019-training-data/twitter-english'"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_dirs = next(os.walk(twitter_trainingDev_data_path))[1]"
      ],
      "metadata": {
        "id": "bH426jGqWq0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_dirs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8D49CShXOTG",
        "outputId": "711a296c-c2d5-4a63-c447-7a4cbb34109c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['putinmissing',\n",
              " 'ferguson',\n",
              " 'ebola-essien',\n",
              " 'illary',\n",
              " 'prince-toronto',\n",
              " 'sydneysiege',\n",
              " 'ottawashooting',\n",
              " 'charliehebdo',\n",
              " 'germanwings-crash']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_d1 = []\n",
        "for i in twitter_dirs:\n",
        "  twitter_d1.extend(next(os.walk(twitter_trainingDev_data_path+'/'+i))[1])"
      ],
      "metadata": {
        "id": "ztBb3K9karFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(twitter_d1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOKt_OW6boDl",
        "outputId": "f05e30cf-3205-4599-848b-b7f16feb2e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "325"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def processTwitterSourcePosts(twitter_dataset_path):\n",
        "    twitter_dirs = next(os.walk(twitter_dataset_path))[1]\n",
        "\n",
        "    twitter_dirs_sorted = sorted(twitter_dirs)\n",
        "    \n",
        "    twitter_src_dirs = []\n",
        "    twitter_src_posts = []\n",
        "    \n",
        "    for directory in twitter_dirs_sorted:\n",
        "        tweet_src_path = twitter_dataset_path + '/' + directory + '/source-tweet' #accessing source directories\n",
        "        twitter_src_dirs.append(next(os.walk(tweet_src_path))[2])\n",
        "    \n",
        "    src_tweet_files = []\n",
        "    for sdirs in twitter_src_dirs:\n",
        "        for i in sdirs:\n",
        "            src_tweet_files.append(i)\n",
        "    src_tweet_files_sorted = sorted(src_tweet_files)\n",
        "    \n",
        "    for file in src_tweet_files_sorted:\n",
        "        paths = twitter_dataset_path + '/' + file.split('.')[0] + '/source-tweet' + '/' + file\n",
        "        tweet_post_dict = {}\n",
        "        \n",
        "        \n",
        "        with open(paths) as f:\n",
        "            for line in f:\n",
        "                src = json.loads(line)\n",
        "                text = src['text']\n",
        "                inre = src['in_reply_to_status_id']\n",
        "                tid = src['id']\n",
        "                \n",
        "                tweet_post_dict['text'] = text \n",
        "                tweet_post_dict['id'] = tid   \n",
        "                tweet_post_dict['inre'] = inre\n",
        "                twitter_src_posts.append(tweet_post_dict)\n",
        "  \n",
        "    return twitter_dirs_sorted, twitter_src_posts"
      ],
      "metadata": {
        "id": "UrKXPxvzUFnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_trainDev_dirs_sorted , twitter_trainDev_src_posts = processTwitterSourcePosts(twitter_trainingDev_data_path+\"/charliehebdo\")\n",
        "twitter_trainDev_src_posts_df = pd.DataFrame(twitter_trainDev_src_posts)\n",
        "\n",
        "twitter_test_dirs_sorted , twitter_test_src_posts = processTwitterSourcePosts(twitter_test_data_path+\"/nat-geo-footage\")\n",
        "twitter_test_src_posts_df = pd.DataFrame(twitter_test_src_posts)"
      ],
      "metadata": {
        "id": "yinrbgLFUJWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processTwitterReplyPosts(twitter_dataset_path, twitter_dirs_sorted):\n",
        "    replies_files = []\n",
        "    twitter_replies = []\n",
        "\n",
        "\n",
        "    for directory in twitter_dirs_sorted:\n",
        "        tweet_src_path = twitter_dataset_path + '/' + directory + '/replies'\n",
        "        replies_files.append(next(os.walk(tweet_src_path))[2])\n",
        "        \n",
        "        for i in (next(os.walk(tweet_src_path))[2]):\n",
        "            paths = twitter_dataset_path + '/' + directory + '/replies' + '/' + i\n",
        "            tweet_post_dict = {}\n",
        "            with open(paths) as f:\n",
        "                for line in f:\n",
        "                    src = json.loads(line)\n",
        "                    text = src['text']\n",
        "                    inre = str(src['in_reply_to_status_id'])\n",
        "                    tid = src['id']\n",
        "                    tweet_post_dict['text'] = text         \n",
        "                    tweet_post_dict['id'] = tid            \n",
        "                    tweet_post_dict['inre'] = inre         \n",
        "                    tweet_post_dict['source'] = directory  \n",
        "                    twitter_replies.append(tweet_post_dict)\n",
        "   \n",
        " \n",
        "    return twitter_replies"
      ],
      "metadata": {
        "id": "za5APOFfdlBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_trainDev_replies    = processTwitterReplyPosts(twitter_trainingDev_data_path+\"/charliehebdo\", twitter_trainDev_dirs_sorted)\n",
        "twitter_trainDev_replies_df = pd.DataFrame(twitter_trainDev_replies)\n",
        "\n",
        "twitter_test_replies     = processTwitterReplyPosts(twitter_test_data_path+\"/nat-geo-footage\", twitter_test_dirs_sorted)\n",
        "twitter_test_replies_df  = pd.DataFrame(twitter_test_replies)"
      ],
      "metadata": {
        "id": "eOzJKVqWdtoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def twitterCleanDf(src_posts_df, replies_df):\n",
        "    twitter_data = [src_posts_df, replies_df]\n",
        "\n",
        "    twitter_data = pd.concat(twitter_data)\n",
        "\n",
        "    twitter_data['id']   = twitter_data.id.astype(str)\n",
        "    twitter_data['inre'] = twitter_data.inre.astype(str)\n",
        "\n",
        "    twitter_clean_data = pd.DataFrame(twitter_data)\n",
        "\n",
        "    twitter_clean_data.id   = twitter_clean_data.id.str.strip()      \n",
        "    twitter_clean_data.inre = twitter_clean_data.inre.str.strip()  \n",
        "    return twitter_clean_data"
      ],
      "metadata": {
        "id": "BfDvrekId5DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_clean_trainDev_df = twitterCleanDf(twitter_trainDev_src_posts_df, twitter_trainDev_replies_df)\n",
        "twitter_clean_test_df     = twitterCleanDf(twitter_test_src_posts_df, twitter_test_replies_df)\n",
        "\n",
        "twitter_train_withKeys_df = pd.merge(twitter_clean_trainDev_df, twitter_train_key_df, how = 'inner', on = \"id\", )\n",
        "twitter_dev_withKeys_df   = pd.merge(twitter_clean_trainDev_df, twitter_dev_key_df, how = 'inner', on = \"id\", )\n",
        "twitter_test_withKeys_df  = pd.merge(twitter_clean_test_df, twitter_test_key_df, how = 'inner', on = \"id\", )"
      ],
      "metadata": {
        "id": "kIbU3GAue6f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetchTwitterDataset(twitter_withKeys_df):\n",
        "    \n",
        "    twitter_df       = twitter_withKeys_df[['id', 'text']].copy()\n",
        "    twitter_df_new   = twitter_df.rename(columns={'id': 'inre', 'text': 'inreText'})\n",
        "    twitter_df_new1  = twitter_df.rename(columns={'id': 'source', 'text': 'sourceText'})\n",
        "    twitter_dataset  = pd.merge(twitter_withKeys_df, twitter_df_new, how = 'left', on = \"inre\", )\n",
        "    twitter_dataset1 = pd.merge(twitter_withKeys_df, twitter_df_new1, how = 'left', on = \"source\", )\n",
        "    \n",
        "    return twitter_dataset, twitter_dataset1"
      ],
      "metadata": {
        "id": "rEdgPlwVfDNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_train_dataset_inre, twitter_train_dataset_src = fetchTwitterDataset(twitter_train_withKeys_df)\n",
        "twitter_dev_dataset_inre, twitter_dev_dataset_src= fetchTwitterDataset(twitter_dev_withKeys_df)\n",
        "twitter_test_dataset_inre, twitter_test_dataset_src = fetchTwitterDataset(twitter_test_withKeys_df)\n",
        "\n",
        "\n",
        "twitter_train_dataset_src = pd.merge(twitter_train_dataset_inre, twitter_train_dataset_src, how = 'inner', on = \"id\",)\n",
        "twitter_dev_dataset_src = pd.merge(twitter_dev_dataset_inre, twitter_dev_dataset_src, how = 'inner', on = \"id\",)\n",
        "twitter_test_dataset_src = pd.merge(twitter_test_dataset_inre, twitter_test_dataset_src, how = 'inner', on = \"id\",)\n",
        "\n",
        "twitter_new_train_data_df = twitter_train_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()\n",
        "twitter_new_dev_data_df = twitter_dev_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()\n",
        "twitter_new_test_data_df = twitter_test_dataset_src[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','inreText', 'sourceText' ]].copy()"
      ],
      "metadata": {
        "id": "J4xa71u1fG8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeRedundantData(twitter_df):\n",
        "    for i in range(0,len(twitter_df)):\n",
        "        if twitter_df['inre_x'][i] == twitter_df['source_x'][i]:\n",
        "            twitter_df['sourceText'][i] = np.nan\n",
        "    return twitter_df\n",
        "\n",
        "twitter_new_train_data_df = removeRedundantData(twitter_new_train_data_df)\n",
        "twitter_new_dev_data_df   = removeRedundantData(twitter_new_dev_data_df)\n",
        "twitter_new_test_data_df  = removeRedundantData(twitter_new_test_data_df)"
      ],
      "metadata": {
        "id": "hfsVowCtfJsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_new_train_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterTrainDataSrc.csv', encoding='utf-8', index=False)\n",
        "twitter_new_dev_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterDevDataSrc.csv', encoding='utf-8', index=False)\n",
        "twitter_new_test_data_df.to_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterTestDataSrc.csv', encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "I2IPH81yfMq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def label_to_int(label):\n",
        "  if label   == 'support':\n",
        "    return 0\n",
        "  elif label == 'deny':\n",
        "    return 1\n",
        "  elif label == 'query':\n",
        "    return 2\n",
        "  elif label == 'comment':\n",
        "    return 3\n",
        "\n",
        "\n",
        "def processText(text):\n",
        "  text = re.sub(r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\", \"$URL$\",text.strip())\n",
        "  text = re.sub(r\"(@[A-Za-z0-9]+)\", \"$MENTION$\", text.strip())\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "IhNzXe1AfTVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    \n",
        "def processStanceData(twitterDf, RedditDf):\n",
        "  frames = [twitterDf, RedditDf]\n",
        "\n",
        "  resultDf = pd.concat(frames)                                                     \n",
        "  result1  = resultDf.replace(np.nan, '', regex=True)                               \n",
        "\n",
        "  result1['labelvalue'] = result1.label_x.apply(label_to_int)                      \n",
        "  result1['SrcInre']    = result1['inreText'].str.cat(result1['sourceText'],sep=\" \")\n",
        "\n",
        "  data = result1[['text_x', 'id', 'inre_x', 'source_x' ,'label_x','SrcInre', 'labelvalue' ]].copy()\n",
        "\n",
        "\n",
        " \n",
        "\n",
        "  data.columns = ['replyText', 'replyTextId', 'previousText', 'sourceText', 'label', 'previousPlusSrcText', 'labelValue']\n",
        "\n",
        "  data['pReplyText']           = data.replyText.apply(processText)\n",
        "  data['pPreviousPlusSrcText'] = data.previousPlusSrcText.apply(processText)\n",
        "  data['TextSrcInre']          = data['pReplyText'].str.cat(data['pPreviousPlusSrcText'],sep=\" \")\n",
        "  return data"
      ],
      "metadata": {
        "id": "aP5NL1xHhSfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "twitterTrainDf = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterTrainDataSrc.csv')\n",
        "redditTrainDf  = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/RedditTrainDataSrc.csv')\n",
        "\n",
        "twitterDevDf   = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterDevDataSrc.csv')\n",
        "redditDevDf    = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/RedditDevDataSrc.csv')\n",
        "\n",
        "twitterTestDf  = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/TwitterTestDataSrc.csv')\n",
        "redditTestDf   = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/RedditTestDataSrc.csv')\n",
        "\n",
        "trainDf = processStanceData(twitterTrainDf, redditTrainDf)\n",
        "trainDf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "zn8DBd8_hV0w",
        "outputId": "4938c051-09a8-4c89-e5c9-9f3b591a6cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f26f585-bdaf-49dc-8dc2-7eb1c5382299\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "      <th>TextSrcInre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
              "      <td>552783667052167168.0</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
              "      <td></td>\n",
              "      <td>France: 10 people dead after shooting at HQ of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
              "      <td>552785375161499648.0</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
              "      <td></td>\n",
              "      <td>BREAKING: 10 reportedly shot dead at Paris HQ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BREAKING: At least 10 killed in shooting at Fr...</td>\n",
              "      <td>552791196247269376.0</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>BREAKING: At least 10 killed in shooting at Fr...</td>\n",
              "      <td></td>\n",
              "      <td>BREAKING: At least 10 killed in shooting at Fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Eleven dead in shooting at Paris offices of sa...</td>\n",
              "      <td>552791578893619200.0</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>Eleven dead in shooting at Paris offices of sa...</td>\n",
              "      <td></td>\n",
              "      <td>Eleven dead in shooting at Paris offices of sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BREAKING Charlie Hebdo latest: 11 dead 10 woun...</td>\n",
              "      <td>552792544132997120.0</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0.0</td>\n",
              "      <td>BREAKING Charlie Hebdo latest: 11 dead 10 woun...</td>\n",
              "      <td></td>\n",
              "      <td>BREAKING Charlie Hebdo latest: 11 dead 10 woun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>&amp;gt; That isn't disputed, it's that he came to...</td>\n",
              "      <td>e2bmzf2</td>\n",
              "      <td>e2bmcct</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>That isn't disputed, it's that he came to Scot...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>&amp;gt; That isn't disputed, it's that he came to...</td>\n",
              "      <td>That isn't disputed, it's that he came to Scot...</td>\n",
              "      <td>&amp;gt; That isn't disputed, it's that he came to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>694</th>\n",
              "      <td>In the press conference earlier today he said ...</td>\n",
              "      <td>e2bos7p</td>\n",
              "      <td>e2bo412</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>deny</td>\n",
              "      <td>There is no point to any of this.         Jon ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>In the press conference earlier today he said ...</td>\n",
              "      <td>There is no point to any of this.         Jon ...</td>\n",
              "      <td>In the press conference earlier today he said ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>e2btp0f</td>\n",
              "      <td>e2bta92</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>Lol it doesn't though Jon Sopel: Bizarre. @rea...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[deleted]</td>\n",
              "      <td>Lol it doesn't though Jon Sopel: Bizarre. $MEN...</td>\n",
              "      <td>[deleted] Lol it doesn't though Jon Sopel: Biz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>696</th>\n",
              "      <td>[deleted]</td>\n",
              "      <td>e2bxvw0</td>\n",
              "      <td>e2bxjzw</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>It's just another of the many \"factual errors\"...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>[deleted]</td>\n",
              "      <td>It's just another of the many \"factual errors\"...</td>\n",
              "      <td>[deleted] It's just another of the many \"factu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>697</th>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "      <td>e2c1n3o</td>\n",
              "      <td>e2bv4kg</td>\n",
              "      <td>8yktu5</td>\n",
              "      <td>comment</td>\n",
              "      <td>[This is the better tweet](https://twitter.com...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "      <td>[This is the better tweet]($URL$): he left the...</td>\n",
              "      <td>Yeah seems like he is either blatantly lying o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1770 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f26f585-bdaf-49dc-8dc2-7eb1c5382299')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f26f585-bdaf-49dc-8dc2-7eb1c5382299 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f26f585-bdaf-49dc-8dc2-7eb1c5382299');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             replyText  ...                                        TextSrcInre\n",
              "0    France: 10 people dead after shooting at HQ of...  ...  France: 10 people dead after shooting at HQ of...\n",
              "1    BREAKING: 10 reportedly shot dead at Paris HQ ...  ...  BREAKING: 10 reportedly shot dead at Paris HQ ...\n",
              "2    BREAKING: At least 10 killed in shooting at Fr...  ...  BREAKING: At least 10 killed in shooting at Fr...\n",
              "3    Eleven dead in shooting at Paris offices of sa...  ...  Eleven dead in shooting at Paris offices of sa...\n",
              "4    BREAKING Charlie Hebdo latest: 11 dead 10 woun...  ...  BREAKING Charlie Hebdo latest: 11 dead 10 woun...\n",
              "..                                                 ...  ...                                                ...\n",
              "693  &gt; That isn't disputed, it's that he came to...  ...  &gt; That isn't disputed, it's that he came to...\n",
              "694  In the press conference earlier today he said ...  ...  In the press conference earlier today he said ...\n",
              "695                                          [deleted]  ...  [deleted] Lol it doesn't though Jon Sopel: Biz...\n",
              "696                                          [deleted]  ...  [deleted] It's just another of the many \"factu...\n",
              "697  Yeah seems like he is either blatantly lying o...  ...  Yeah seems like he is either blatantly lying o...\n",
              "\n",
              "[1770 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "devDf = processStanceData(twitterDevDf, redditDevDf)\n",
        "devDf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DdtPp2tLhxjg",
        "outputId": "7516bf50-cdb5-4959-9ac4-eff7011b0e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f7b85264-c6ff-4988-b7bd-5fbcf3980d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "      <th>TextSrcInre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Appalled by the attack on Charlie Hebdo in Par...</td>\n",
              "      <td>552788945017516032</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Appalled by the attack on Charlie Hebdo in Par...</td>\n",
              "      <td></td>\n",
              "      <td>Appalled by the attack on Charlie Hebdo in Par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Reports of fatality and injuries following sho...</td>\n",
              "      <td>553480082996879360</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>Reports of fatality and injuries following sho...</td>\n",
              "      <td></td>\n",
              "      <td>Reports of fatality and injuries following sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#BREAKING Paris hostage-taker 'knows' one Char...</td>\n",
              "      <td>553553288625672192</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>#BREAKING Paris hostage-taker 'knows' one Char...</td>\n",
              "      <td></td>\n",
              "      <td>#BREAKING Paris hostage-taker 'knows' one Char...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BREAKING: Police order all shops closed in fam...</td>\n",
              "      <td>553561170637238272</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>BREAKING: Police order all shops closed in fam...</td>\n",
              "      <td></td>\n",
              "      <td>BREAKING: Police order all shops closed in fam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@UnbiasedF If you go into such facts it will b...</td>\n",
              "      <td>552797821188206592</td>\n",
              "      <td>552796424266854400</td>\n",
              "      <td>552788945017516032.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>@m33ryg @tnewtondunn @mehdirhasan Can you supp...</td>\n",
              "      <td>3</td>\n",
              "      <td>$MENTION$ If you go into such facts it will be...</td>\n",
              "      <td>$MENTION$ $MENTION$ $MENTION$ Can you supply t...</td>\n",
              "      <td>$MENTION$ If you go into such facts it will be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>Remember the fluorides in our water replaces w...</td>\n",
              "      <td>e3bk3q8</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>3</td>\n",
              "      <td>Remember the fluorides in our water replaces w...</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>Remember the fluorides in our water replaces w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>We evolved as omnivores, but I do agree with y...</td>\n",
              "      <td>e3ay5vh</td>\n",
              "      <td>e3ak72f</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Oh they put iodine in salt here in Latin Ameri...</td>\n",
              "      <td>3</td>\n",
              "      <td>We evolved as omnivores, but I do agree with y...</td>\n",
              "      <td>Oh they put iodine in salt here in Latin Ameri...</td>\n",
              "      <td>We evolved as omnivores, but I do agree with y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>&amp;gt; 7 drops in about a double shot of cold wa...</td>\n",
              "      <td>e3c5joo</td>\n",
              "      <td>e3bqum8</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>I do about 7 drops in about a double shot of c...</td>\n",
              "      <td>3</td>\n",
              "      <td>&amp;gt; 7 drops in about a double shot of cold wa...</td>\n",
              "      <td>I do about 7 drops in about a double shot of c...</td>\n",
              "      <td>&amp;gt; 7 drops in about a double shot of cold wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>The book The Iodine Crisis is really good and ...</td>\n",
              "      <td>e3bq78h</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>support</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>0</td>\n",
              "      <td>The book The Iodine Crisis is really good and ...</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>The book The Iodine Crisis is really good and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>Iodine definitely degrades from iodized salt.</td>\n",
              "      <td>e3b6bd7</td>\n",
              "      <td>e3b3p2h</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>comment</td>\n",
              "      <td>Edit: we've found this comment to likely be te...</td>\n",
              "      <td>3</td>\n",
              "      <td>Iodine definitely degrades from iodized salt.</td>\n",
              "      <td>Edit: we've found this comment to likely be te...</td>\n",
              "      <td>Iodine definitely degrades from iodized salt. ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>529 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7b85264-c6ff-4988-b7bd-5fbcf3980d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7b85264-c6ff-4988-b7bd-5fbcf3980d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7b85264-c6ff-4988-b7bd-5fbcf3980d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             replyText  ...                                        TextSrcInre\n",
              "0    Appalled by the attack on Charlie Hebdo in Par...  ...  Appalled by the attack on Charlie Hebdo in Par...\n",
              "1    Reports of fatality and injuries following sho...  ...  Reports of fatality and injuries following sho...\n",
              "2    #BREAKING Paris hostage-taker 'knows' one Char...  ...  #BREAKING Paris hostage-taker 'knows' one Char...\n",
              "3    BREAKING: Police order all shops closed in fam...  ...  BREAKING: Police order all shops closed in fam...\n",
              "4    @UnbiasedF If you go into such facts it will b...  ...  $MENTION$ If you go into such facts it will be...\n",
              "..                                                 ...  ...                                                ...\n",
              "431  Remember the fluorides in our water replaces w...  ...  Remember the fluorides in our water replaces w...\n",
              "432  We evolved as omnivores, but I do agree with y...  ...  We evolved as omnivores, but I do agree with y...\n",
              "433  &gt; 7 drops in about a double shot of cold wa...  ...  &gt; 7 drops in about a double shot of cold wa...\n",
              "434  The book The Iodine Crisis is really good and ...  ...  The book The Iodine Crisis is really good and ...\n",
              "435      Iodine definitely degrades from iodized salt.  ...  Iodine definitely degrades from iodized salt. ...\n",
              "\n",
              "[529 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "testDf = processStanceData(twitterTestDf, redditTestDf)\n",
        "testDf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "ZAvrvJtsh25_",
        "outputId": "230c98a4-53d0-4816-d847-274846b399a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3cbba723-22f6-4a7d-94b3-336e8edba6ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>replyText</th>\n",
              "      <th>replyTextId</th>\n",
              "      <th>previousText</th>\n",
              "      <th>sourceText</th>\n",
              "      <th>label</th>\n",
              "      <th>previousPlusSrcText</th>\n",
              "      <th>labelValue</th>\n",
              "      <th>pReplyText</th>\n",
              "      <th>pPreviousPlusSrcText</th>\n",
              "      <th>TextSrcInre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"National Geographic channel has paid $ 1 mill...</td>\n",
              "      <td>934715071757819904</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>\"National Geographic channel has paid $ 1 mill...</td>\n",
              "      <td></td>\n",
              "      <td>\"National Geographic channel has paid $ 1 mill...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"@KenyanTraffic: \"National Geographic channel ...</td>\n",
              "      <td>934828842505723904</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>\"$MENTION$: \"National Geographic channel has p...</td>\n",
              "      <td></td>\n",
              "      <td>\"$MENTION$: \"National Geographic channel has p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>National Geographic channel has paid   $ 1 mil...</td>\n",
              "      <td>941305217454403584</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>National Geographic channel has paid   $ 1 mil...</td>\n",
              "      <td></td>\n",
              "      <td>National Geographic channel has paid   $ 1 mil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>National Geographic channel has reportedly pai...</td>\n",
              "      <td>944339600998326274</td>\n",
              "      <td>None</td>\n",
              "      <td></td>\n",
              "      <td>support</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>National Geographic channel has reportedly pai...</td>\n",
              "      <td></td>\n",
              "      <td>National Geographic channel has reportedly pai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@KenyanTraffic @LalitKModi @Gidi_Traffic Waoh....</td>\n",
              "      <td>934747500526874624</td>\n",
              "      <td>934715071757819904</td>\n",
              "      <td>934715071757819904.0</td>\n",
              "      <td>comment</td>\n",
              "      <td>\"National Geographic channel has paid $ 1 mill...</td>\n",
              "      <td>3</td>\n",
              "      <td>$MENTION$ $MENTION$ $MENTION$_Traffic Waoh...I...</td>\n",
              "      <td>\"National Geographic channel has paid $ 1 mill...</td>\n",
              "      <td>$MENTION$ $MENTION$ $MENTION$_Traffic Waoh...I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>Sometimes you can't win an argument. :-)\\n\\nAm...</td>\n",
              "      <td>c5nsrhe</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>3</td>\n",
              "      <td>Sometimes you can't win an argument. :-)\\n\\nAm...</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>Sometimes you can't win an argument. :-)\\n\\nAm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>757</th>\n",
              "      <td>I'm not a troll.. I figured it was bullshit, b...</td>\n",
              "      <td>c5nsqr2</td>\n",
              "      <td>c5nspru</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>Just in case this isn't just a troll\\n\\n- Obam...</td>\n",
              "      <td>3</td>\n",
              "      <td>I'm not a troll.. I figured it was bullshit, b...</td>\n",
              "      <td>Just in case this isn't just a troll\\n\\n- Obam...</td>\n",
              "      <td>I'm not a troll.. I figured it was bullshit, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>Just in case this isn't just a troll\\n\\n- Obam...</td>\n",
              "      <td>c5nspru</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>3</td>\n",
              "      <td>Just in case this isn't just a troll\\n\\n- Obam...</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>Just in case this isn't just a troll\\n\\n- Obam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>Right-wing republicans? Aren't a lot of them h...</td>\n",
              "      <td>c5nsn66</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>3</td>\n",
              "      <td>Right-wing republicans? Aren't a lot of them h...</td>\n",
              "      <td>I've been searching, and can't find a single c...</td>\n",
              "      <td>Right-wing republicans? Aren't a lot of them h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>760</th>\n",
              "      <td>Yeah, they completely ignored my post. Even th...</td>\n",
              "      <td>c5nst14</td>\n",
              "      <td>c5nsrhe</td>\n",
              "      <td>xn2bn</td>\n",
              "      <td>comment</td>\n",
              "      <td>Sometimes you can't win an argument. :-)\\n\\nAm...</td>\n",
              "      <td>3</td>\n",
              "      <td>Yeah, they completely ignored my post. Even th...</td>\n",
              "      <td>Sometimes you can't win an argument. :-)\\n\\nAm...</td>\n",
              "      <td>Yeah, they completely ignored my post. Even th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>910 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3cbba723-22f6-4a7d-94b3-336e8edba6ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3cbba723-22f6-4a7d-94b3-336e8edba6ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3cbba723-22f6-4a7d-94b3-336e8edba6ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             replyText  ...                                        TextSrcInre\n",
              "0    \"National Geographic channel has paid $ 1 mill...  ...  \"National Geographic channel has paid $ 1 mill...\n",
              "1    \"@KenyanTraffic: \"National Geographic channel ...  ...  \"$MENTION$: \"National Geographic channel has p...\n",
              "2    National Geographic channel has paid   $ 1 mil...  ...  National Geographic channel has paid   $ 1 mil...\n",
              "3    National Geographic channel has reportedly pai...  ...  National Geographic channel has reportedly pai...\n",
              "4    @KenyanTraffic @LalitKModi @Gidi_Traffic Waoh....  ...  $MENTION$ $MENTION$ $MENTION$_Traffic Waoh...I...\n",
              "..                                                 ...  ...                                                ...\n",
              "756  Sometimes you can't win an argument. :-)\\n\\nAm...  ...  Sometimes you can't win an argument. :-)\\n\\nAm...\n",
              "757  I'm not a troll.. I figured it was bullshit, b...  ...  I'm not a troll.. I figured it was bullshit, b...\n",
              "758  Just in case this isn't just a troll\\n\\n- Obam...  ...  Just in case this isn't just a troll\\n\\n- Obam...\n",
              "759  Right-wing republicans? Aren't a lot of them h...  ...  Right-wing republicans? Aren't a lot of them h...\n",
              "760  Yeah, they completely ignored my post. Even th...  ...  Yeah, they completely ignored my post. Even th...\n",
              "\n",
              "[910 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = trainDf['TextSrcInre'].tolist()\n",
        "y_train = trainDf['labelValue'].tolist()\n",
        "\n",
        "\n",
        "x_dev  = devDf['TextSrcInre'].tolist()\n",
        "y_dev  = devDf['labelValue'].tolist()\n",
        "x_test = testDf['TextSrcInre'].tolist()\n",
        "y_test = testDf['labelValue'].tolist()\n",
        "\n",
        "#Instantiating TfidfVectorizer object and fitting it on the training set\n",
        "tfidf         = TfidfVectorizer(min_df = 10, max_df = 0.5, ngram_range=(1,2))\n",
        "x_train_feats = tfidf.fit_transform(x_train)\n",
        "\n",
        "print(x_train_feats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfj4ASUOh5X7",
        "outputId": "b13b56fb-a16e-4d0e-e3d2-4b00ede89a77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 54)\t0.2961078206082725\n",
            "  (0, 1398)\t0.25769442938989356\n",
            "  (0, 905)\t0.282676917693621\n",
            "  (0, 211)\t0.2961078206082725\n",
            "  (0, 1756)\t0.21630594560940444\n",
            "  (0, 2360)\t0.2633683425719235\n",
            "  (0, 2108)\t0.08652395767949313\n",
            "  (0, 53)\t0.2961078206082725\n",
            "  (0, 412)\t0.10384043347351882\n",
            "  (0, 1329)\t0.2386008839179131\n",
            "  (0, 2297)\t0.3044715492663311\n",
            "  (0, 1693)\t0.17570591896097137\n",
            "  (0, 1376)\t0.08723161600710759\n",
            "  (0, 904)\t0.282676917693621\n",
            "  (0, 208)\t0.10735377481694162\n",
            "  (0, 1755)\t0.1623568901334913\n",
            "  (0, 71)\t0.172998989831333\n",
            "  (0, 495)\t0.15380913270448754\n",
            "  (0, 1497)\t0.1424132199018204\n",
            "  (0, 2)\t0.1939621385872572\n",
            "  (0, 696)\t0.19705999212582448\n",
            "  (1, 411)\t0.1954324065806648\n",
            "  (1, 216)\t0.25561946290428395\n",
            "  (1, 1765)\t0.3112354312987481\n",
            "  (1, 836)\t0.19509907912459648\n",
            "  :\t:\n",
            "  (1769, 491)\t0.22264309407670407\n",
            "  (1769, 1013)\t0.07247036096112647\n",
            "  (1769, 1045)\t0.07867501913124181\n",
            "  (1769, 1029)\t0.037097198708640255\n",
            "  (1769, 795)\t0.14446994410820022\n",
            "  (1769, 349)\t0.049089211775819604\n",
            "  (1769, 1942)\t0.07419439741728051\n",
            "  (1769, 2307)\t0.051951519951414546\n",
            "  (1769, 1450)\t0.05734379693535802\n",
            "  (1769, 2042)\t0.05173570653616018\n",
            "  (1769, 1439)\t0.08728803106323214\n",
            "  (1769, 2101)\t0.08568989708369981\n",
            "  (1769, 1133)\t0.0752960179960528\n",
            "  (1769, 1352)\t0.042869432715201466\n",
            "  (1769, 355)\t0.05254054084988899\n",
            "  (1769, 2074)\t0.04051112059455325\n",
            "  (1769, 1144)\t0.057245216510334\n",
            "  (1769, 2269)\t0.0972104825179301\n",
            "  (1769, 955)\t0.04860524125896505\n",
            "  (1769, 992)\t0.10135535889672638\n",
            "  (1769, 1429)\t0.04096543513157843\n",
            "  (1769, 125)\t0.07058558109600979\n",
            "  (1769, 1703)\t0.050295996389173786\n",
            "  (1769, 2108)\t0.029899241610902304\n",
            "  (1769, 71)\t0.05978157650357907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FSR8T6KPee0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_feats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXxbKI4Fki-c",
        "outputId": "2e742883-c29d-4bb4-9ee9-d27570094fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1770x2426 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 84077 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDf['TextSrcInre'][0].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLw2eah6obCC",
        "outputId": "8ee97980-61fa-4782-c69d-03f51a140cfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['France: 10 people dead after shooting at HQ of satirical weekly newspaper #CharlieHebdo, according to witnesses $URL$ ',\n",
              " \"Even ants won't eat aspartame! \"]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainDf['labelValue'][0].tolist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wLfhv68oqlT",
        "outputId": "517d2de3-1e90-47f8-900e-e868d9f30cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "73vO8pNnelCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm( kernel='rbf')\n",
        "clf.fit(x_train_feats, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "id": "qZFklK-Dl1eX",
        "outputId": "bc7a542c-6fac-4ae0-e096-5196b9fae214"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ac2a0d8ef217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "SFeoEKpC30-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(x_train_feats, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "6B7b89eAmvXl",
        "outputId": "8525d034-9b0d-4814-a993-5b9886583302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f168a14597d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNaive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNaive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \"\"\"\n\u001b[0;32m--> 663\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0;34m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = trainDf['TextSrcInre'].tolist()\n",
        "y_train = trainDf['labelValue'].tolist()\n",
        "\n",
        "\n",
        "x_dev  = devDf['TextSrcInre'].tolist()\n",
        "y_dev  = devDf['labelValue'].tolist()\n",
        "x_test = testDf['TextSrcInre'].tolist()\n",
        "y_test = testDf['labelValue'].tolist()"
      ],
      "metadata": {
        "id": "0qoahLz7m-gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_vectorizer=TfidfVectorizer(ngram_range=(1,3))\n",
        "x_train_tfidf=tf_vectorizer.fit_transform(trainDf)\n",
        "#x_test_tfidf=tf_vectorizer.transform(x_test)"
      ],
      "metadata": {
        "id": "94AqQC71pvyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = svm.LinearSVC()\n",
        "clf.fit(x_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "6J4YJrX2p2CI",
        "outputId": "eea2efca-63a0-412e-8813-0373ba6ce06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-5b2c1a6923a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_tfidf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         )\n\u001b[1;32m    254\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    977\u001b[0m     )\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulti_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_y\u001b[0;34m(y, multi_output, y_numeric)\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tfidf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRIhG63Np5FR",
        "outputId": "f6a66d66-996c-4eca-e25c-e75d85a481a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<10x10 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 10 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qOJR_juJp8C8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}