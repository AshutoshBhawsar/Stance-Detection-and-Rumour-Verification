{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TASKB_LSTM_MILESTONE3",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mU8lKhWTF29Y"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "from keras.layers import LSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MAX_SEQUENCE_LENGTH = 512\n",
        "MAX_NB_WORDS = 2000\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "\n",
        "data_train = pd.read_csv('/content/drive/MyDrive/NLP/csvfiles/dataFile.csv')"
      ],
      "metadata": {
        "id": "3nsU1MsmJZwa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = data_train.drop('Unnamed: 0',axis=1)"
      ],
      "metadata": {
        "id": "e4vhqnhjJsgQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Dd0x0S1b24qO",
        "outputId": "c613bf81-3154-4374-cbb0-59f293d90776"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       type                  id  \\\n",
              "0    source  529660296080916480   \n",
              "1    source  529653029747064832   \n",
              "2    source  529687410611728384   \n",
              "3    source  529713467184676864   \n",
              "4    source  529689679411810304   \n",
              "..      ...                 ...   \n",
              "360  source              6hb6b3   \n",
              "361  source              7d28gk   \n",
              "362  source              83ddtk   \n",
              "363  source              8j9s33   \n",
              "364  source              934q6t   \n",
              "\n",
              "                                                  text   ups  label_a  label_b  \n",
              "0    Prince is playing a secret show in Toronto ton...    47        0      0.0  \n",
              "1    Prince fans lining up at Massey Hall. Wristban...     7        0      0.0  \n",
              "2    Is it true? Prince rumoured to be performing s...     8        3      0.0  \n",
              "3    Secret Prince show rumored for Toronto tonight...    37        0      0.0  \n",
              "4    People talking about stupid shit like governme...     5        0      0.0  \n",
              "..                                                 ...   ...      ...      ...  \n",
              "360  Is it true the Earth is flat? Is there proof? ...     0        1      1.0  \n",
              "361  Is it true that some people in America gets ja...     0        1      0.0  \n",
              "362  Oh sweet and wholesome Reddit, is it true US c...     0        1      2.0  \n",
              "363  Face facts: Immigrants commit fewer crimes tha...  1442        0      0.0  \n",
              "364  Iodine increases IQ and is an essential part o...   196        0      1.0  \n",
              "\n",
              "[365 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28d1744b-fb73-48b5-90d8-1f66691c75db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>ups</th>\n",
              "      <th>label_a</th>\n",
              "      <th>label_b</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>source</td>\n",
              "      <td>529660296080916480</td>\n",
              "      <td>Prince is playing a secret show in Toronto ton...</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>source</td>\n",
              "      <td>529653029747064832</td>\n",
              "      <td>Prince fans lining up at Massey Hall. Wristban...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>source</td>\n",
              "      <td>529687410611728384</td>\n",
              "      <td>Is it true? Prince rumoured to be performing s...</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>source</td>\n",
              "      <td>529713467184676864</td>\n",
              "      <td>Secret Prince show rumored for Toronto tonight...</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>source</td>\n",
              "      <td>529689679411810304</td>\n",
              "      <td>People talking about stupid shit like governme...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>source</td>\n",
              "      <td>6hb6b3</td>\n",
              "      <td>Is it true the Earth is flat? Is there proof? ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>source</td>\n",
              "      <td>7d28gk</td>\n",
              "      <td>Is it true that some people in America gets ja...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>source</td>\n",
              "      <td>83ddtk</td>\n",
              "      <td>Oh sweet and wholesome Reddit, is it true US c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>source</td>\n",
              "      <td>8j9s33</td>\n",
              "      <td>Face facts: Immigrants commit fewer crimes tha...</td>\n",
              "      <td>1442</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>source</td>\n",
              "      <td>934q6t</td>\n",
              "      <td>Iodine increases IQ and is an essential part o...</td>\n",
              "      <td>196</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>365 rows Ã— 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28d1744b-fb73-48b5-90d8-1f66691c75db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28d1744b-fb73-48b5-90d8-1f66691c75db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28d1744b-fb73-48b5-90d8-1f66691c75db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "texts = []\n",
        "labels = []\n",
        "\n",
        "for i in range(data_train.text.shape[0]):\n",
        "   \n",
        "        texts.append(str(data_train.text[i]))\n",
        "        labels.append(data_train.label_b[i])"
      ],
      "metadata": {
        "id": "vPvAU5-yKBES"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "labels = to_categorical(np.asarray(labels),num_classes = 3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJgK-nLFKFpS",
        "outputId": "ad05def4-4808-45ce-86d3-c19814acef1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1665 unique tokens.\n",
            "Shape of data tensor: (365, 512)\n",
            "Shape of label tensor: (365, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88jIUor13c83",
        "outputId": "b82fcec8-6951-4959-d4ab-d85e73e55b69"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split( data[indices], labels[indices], test_size=0.20, random_state=1)\n"
      ],
      "metadata": {
        "id": "JbZfh1MXKVLw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcovBj17aa5_",
        "outputId": "5aed1b99-626e-426e-d114-eb49a725a358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/NLP/test/testsam/glove.6B.100d.txt') as f:\n",
        "    for line in f:\n",
        "        word = line.split()[0]\n",
        "        coefs = np.asarray(line.split()[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Total %s word vectors in Glove.' % len(embeddings_index))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSti0256KZdg",
        "outputId": "66360c37-beb6-4af2-815d-37d1d266e4f7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 400000 word vectors in Glove.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for w, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(w)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "GS0uFD7Bw-fF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGTJpjhF4H8u",
        "outputId": "3f4b56cc-086e-423b-f961-22b93ad52d94"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  133, 1376,    1],\n",
              "       [   0,    0,    0, ...,   17,   92,    2],\n",
              "       [   0,    0,    0, ..., 1360, 1361,    1],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,   14,    2,    1],\n",
              "       [   0,    0,    0, ...,    7,  174,    2],\n",
              "       [   0,    0,    0, ...,    5,  270,    2]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[row[-2] for row in X_train1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6b5530p4cdM",
        "outputId": "94fdc942-2469-4af5-f779-d8cd91ddde31"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47,\n",
              " 7,\n",
              " 8,\n",
              " 37,\n",
              " 5,\n",
              " 1,\n",
              " 9,\n",
              " 4,\n",
              " 8,\n",
              " 7,\n",
              " 5,\n",
              " 49,\n",
              " 70,\n",
              " 101,\n",
              " 7,\n",
              " 19,\n",
              " 28,\n",
              " 54,\n",
              " 181,\n",
              " 60,\n",
              " 89,\n",
              " 416,\n",
              " 41,\n",
              " 73,\n",
              " 97,\n",
              " 17,\n",
              " 279,\n",
              " 187,\n",
              " 331,\n",
              " 85,\n",
              " 21,\n",
              " 127,\n",
              " 6,\n",
              " 13,\n",
              " 224,\n",
              " 20,\n",
              " 58,\n",
              " 118,\n",
              " 130,\n",
              " 56,\n",
              " 201,\n",
              " 250,\n",
              " 247,\n",
              " 68,\n",
              " 20,\n",
              " 10,\n",
              " 35,\n",
              " 20,\n",
              " 13,\n",
              " 54,\n",
              " 14,\n",
              " 194,\n",
              " 145,\n",
              " 30,\n",
              " 134,\n",
              " 11,\n",
              " 36,\n",
              " 65,\n",
              " 66,\n",
              " 144,\n",
              " 232,\n",
              " 351,\n",
              " 23,\n",
              " 20,\n",
              " 129,\n",
              " 28,\n",
              " 80,\n",
              " 80,\n",
              " 12,\n",
              " 312,\n",
              " 32,\n",
              " 10,\n",
              " 45,\n",
              " 24,\n",
              " 94,\n",
              " 2123,\n",
              " 97,\n",
              " 153,\n",
              " 34,\n",
              " 1114,\n",
              " 189,\n",
              " 462,\n",
              " 1635,\n",
              " 62,\n",
              " 94,\n",
              " 9,\n",
              " 3,\n",
              " 42,\n",
              " 33,\n",
              " 21,\n",
              " 10,\n",
              " 4,\n",
              " 53,\n",
              " 32,\n",
              " 523,\n",
              " 5,\n",
              " 202,\n",
              " 39,\n",
              " 684,\n",
              " 14,\n",
              " 10,\n",
              " 17,\n",
              " 10,\n",
              " 22,\n",
              " 17,\n",
              " 497,\n",
              " 15,\n",
              " 5,\n",
              " 1,\n",
              " 17,\n",
              " 8,\n",
              " 7,\n",
              " 85,\n",
              " 328,\n",
              " 50,\n",
              " 98,\n",
              " 5,\n",
              " 41,\n",
              " 55,\n",
              " 43,\n",
              " 57,\n",
              " 142,\n",
              " 64,\n",
              " 91,\n",
              " 18,\n",
              " 171,\n",
              " 28,\n",
              " 19,\n",
              " 20,\n",
              " 69,\n",
              " 28,\n",
              " 215,\n",
              " 601,\n",
              " 38,\n",
              " 40,\n",
              " 108,\n",
              " 41,\n",
              " 192,\n",
              " 37,\n",
              " 39,\n",
              " 40,\n",
              " 17,\n",
              " 27,\n",
              " 572,\n",
              " 33,\n",
              " 160,\n",
              " 25,\n",
              " 27,\n",
              " 65,\n",
              " 63,\n",
              " 24,\n",
              " 53,\n",
              " 42,\n",
              " 58,\n",
              " 22,\n",
              " 78,\n",
              " 23,\n",
              " 30,\n",
              " 19,\n",
              " 596,\n",
              " 31,\n",
              " 28,\n",
              " 698,\n",
              " 69,\n",
              " 28,\n",
              " 44,\n",
              " 11,\n",
              " 17,\n",
              " 28,\n",
              " 21,\n",
              " 38,\n",
              " 119,\n",
              " 31,\n",
              " 18,\n",
              " 84,\n",
              " 32,\n",
              " 33,\n",
              " 268,\n",
              " 38,\n",
              " 38,\n",
              " 131,\n",
              " 27,\n",
              " 17,\n",
              " 43,\n",
              " 32,\n",
              " 318,\n",
              " 18,\n",
              " 183,\n",
              " 78,\n",
              " 28,\n",
              " 123,\n",
              " 14,\n",
              " 69,\n",
              " 20,\n",
              " 45,\n",
              " 30,\n",
              " 39,\n",
              " 32,\n",
              " 18,\n",
              " 55,\n",
              " 47,\n",
              " 76,\n",
              " 32,\n",
              " 9,\n",
              " 142,\n",
              " 52,\n",
              " 23,\n",
              " 130,\n",
              " 24,\n",
              " 24,\n",
              " 241,\n",
              " 33,\n",
              " 20,\n",
              " 112,\n",
              " 275,\n",
              " 51,\n",
              " 33,\n",
              " 91,\n",
              " 66,\n",
              " 56,\n",
              " 60,\n",
              " 1,\n",
              " 45,\n",
              " 45,\n",
              " 138,\n",
              " 267,\n",
              " 43,\n",
              " 33,\n",
              " 58,\n",
              " 61,\n",
              " 53,\n",
              " 146,\n",
              " 100,\n",
              " 88,\n",
              " 20,\n",
              " 51,\n",
              " 41,\n",
              " 22,\n",
              " 35,\n",
              " 76,\n",
              " 20,\n",
              " 106,\n",
              " 70,\n",
              " 45,\n",
              " 49,\n",
              " 113,\n",
              " 34,\n",
              " 133,\n",
              " 49,\n",
              " 27,\n",
              " 98,\n",
              " 79,\n",
              " 22,\n",
              " 34,\n",
              " 29,\n",
              " 56,\n",
              " 67,\n",
              " 57,\n",
              " 220,\n",
              " 45,\n",
              " 38,\n",
              " 20,\n",
              " 55,\n",
              " 178,\n",
              " 48,\n",
              " 111,\n",
              " 43,\n",
              " 60,\n",
              " 33,\n",
              " 52,\n",
              " 53,\n",
              " 35,\n",
              " 173,\n",
              " 79,\n",
              " 185,\n",
              " 75,\n",
              " 137,\n",
              " 420,\n",
              " 38,\n",
              " 62,\n",
              " 10,\n",
              " 40,\n",
              " 48,\n",
              " 37,\n",
              " 41,\n",
              " 77,\n",
              " 69,\n",
              " 65,\n",
              " 62,\n",
              " 86,\n",
              " 52,\n",
              " 38,\n",
              " 83,\n",
              " 58,\n",
              " 46,\n",
              " 41,\n",
              " 99,\n",
              " 137,\n",
              " 23,\n",
              " 67,\n",
              " 101,\n",
              " 98,\n",
              " 428,\n",
              " 201,\n",
              " 187,\n",
              " 154,\n",
              " 217,\n",
              " 93,\n",
              " 119,\n",
              " 60,\n",
              " 46,\n",
              " 114,\n",
              " 73,\n",
              " 33,\n",
              " 141,\n",
              " 50,\n",
              " 13,\n",
              " 2,\n",
              " 36,\n",
              " 4,\n",
              " 26,\n",
              " 0,\n",
              " 20,\n",
              " 0,\n",
              " 4,\n",
              " 18,\n",
              " 17,\n",
              " 20,\n",
              " 9,\n",
              " 201,\n",
              " 20,\n",
              " 18,\n",
              " 58,\n",
              " 3,\n",
              " 62,\n",
              " 21,\n",
              " 1,\n",
              " 121,\n",
              " 19,\n",
              " 20,\n",
              " 1,\n",
              " 0,\n",
              " 22,\n",
              " 21,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 11,\n",
              " 0,\n",
              " 24,\n",
              " 3,\n",
              " 17,\n",
              " 18,\n",
              " 17,\n",
              " 17,\n",
              " 0,\n",
              " 38,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1442,\n",
              " 196]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = Embedding(len(word_index) + 1, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "embedding_vecor_length = 32\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxDJLV5HKfgl",
        "outputId": "855733f1-1279-4f9b-d2d8-1a8771012603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 1000, 100)         166600    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1000, 100)         0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 1000, 32)          16032     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 500, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 500, 64)           6208      \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 250, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 100)               66000     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 100)              400       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 256)               25856     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 357,451\n",
            "Trainable params: 357,251\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "3/3 [==============================] - 18s 935ms/step - loss: 0.6971 - accuracy: 0.3699\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 3s 869ms/step - loss: 0.6574 - accuracy: 0.4932\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 3s 874ms/step - loss: 0.6250 - accuracy: 0.4863\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 3s 941ms/step - loss: 0.6025 - accuracy: 0.4829\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 3s 920ms/step - loss: 0.5989 - accuracy: 0.4829\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 3s 876ms/step - loss: 0.5910 - accuracy: 0.4897\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 3s 896ms/step - loss: 0.5806 - accuracy: 0.5205\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 3s 929ms/step - loss: 0.5556 - accuracy: 0.5342\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 3s 894ms/step - loss: 0.5343 - accuracy: 0.5753\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 3s 918ms/step - loss: 0.5024 - accuracy: 0.6336\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 3s 906ms/step - loss: 0.4683 - accuracy: 0.6918\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 3s 886ms/step - loss: 0.4335 - accuracy: 0.7055\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 3s 943ms/step - loss: 0.4083 - accuracy: 0.7158\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 3s 918ms/step - loss: 0.3651 - accuracy: 0.7877\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 3s 885ms/step - loss: 0.3211 - accuracy: 0.7911\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 3s 881ms/step - loss: 0.3174 - accuracy: 0.7979\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 3s 916ms/step - loss: 0.2709 - accuracy: 0.8390\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 3s 902ms/step - loss: 0.2647 - accuracy: 0.8390\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 3s 928ms/step - loss: 0.2340 - accuracy: 0.8527\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 3s 921ms/step - loss: 0.1821 - accuracy: 0.9075\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 3s 918ms/step - loss: 0.1714 - accuracy: 0.9007\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 3s 874ms/step - loss: 0.1330 - accuracy: 0.9178\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 3s 937ms/step - loss: 0.0995 - accuracy: 0.9486\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 3s 933ms/step - loss: 0.1160 - accuracy: 0.9384\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 3s 891ms/step - loss: 0.1387 - accuracy: 0.9247\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 3s 885ms/step - loss: 0.0947 - accuracy: 0.9486\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 3s 939ms/step - loss: 0.0896 - accuracy: 0.9589\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 3s 890ms/step - loss: 0.0993 - accuracy: 0.9521\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 3s 920ms/step - loss: 0.1069 - accuracy: 0.9418\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0740 - accuracy: 0.9555\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 3s 919ms/step - loss: 0.0943 - accuracy: 0.9623\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 3s 904ms/step - loss: 0.0502 - accuracy: 0.9760\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 3s 923ms/step - loss: 0.0349 - accuracy: 0.9863\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 3s 867ms/step - loss: 0.0517 - accuracy: 0.9795\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 3s 912ms/step - loss: 0.0527 - accuracy: 0.9623\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 3s 879ms/step - loss: 0.0480 - accuracy: 0.9692\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 3s 909ms/step - loss: 0.0454 - accuracy: 0.9829\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 3s 899ms/step - loss: 0.0220 - accuracy: 0.9897\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 3s 881ms/step - loss: 0.0344 - accuracy: 0.9863\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 3s 901ms/step - loss: 0.0424 - accuracy: 0.9795\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 3s 882ms/step - loss: 0.0315 - accuracy: 0.9795\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 3s 944ms/step - loss: 0.0494 - accuracy: 0.9692\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 3s 903ms/step - loss: 0.0261 - accuracy: 0.9897\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 3s 912ms/step - loss: 0.0618 - accuracy: 0.9692\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 3s 923ms/step - loss: 0.0364 - accuracy: 0.9760\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 3s 901ms/step - loss: 0.0272 - accuracy: 0.9863\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 3s 922ms/step - loss: 0.0268 - accuracy: 0.9863\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 3s 939ms/step - loss: 0.0112 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 3s 920ms/step - loss: 0.0334 - accuracy: 0.9863\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 3s 930ms/step - loss: 0.0139 - accuracy: 0.9932\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fef4c329a90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = 0\n",
        "preds = []\n",
        "actual = []\n",
        "\n"
      ],
      "metadata": {
        "id": "HraQgDKT8mcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_preds = model.predict(x_test)\n",
        "\n",
        "for i in range(len(test_preds)):\n",
        "    preds.append(np.argmax(test_preds[i]))\n",
        "    actual.append(np.argmax(y_test[i]))\n",
        "    if np.argmax(test_preds[i])==np.argmax(y_test[i]):\n",
        "        correct_predictions+=1\n",
        "print(\"Correct predictions:\", correct_predictions)\n",
        "print(\"Total number of test examples:\", len(y_test))\n",
        "print(\"Accuracy of model: \", correct_predictions/float(len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFXDr_4lKlLa",
        "outputId": "5220415d-2422-448c-95b7-9ce98c9f086a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct predictions: 36\n",
            "Total number of test examples: 73\n",
            "Accuracy of model:  0.4931506849315068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "YTC8tUcQKp1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score(actual,preds, average='macro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-uNt_VHK8lh",
        "outputId": "993fb599-6c54-4202-9482-e86f413ea491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4237396590337767"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cscoreMLP = []\n",
        "for i in range(len(preds)):\n",
        "    cscoreMLP.append(test_preds[i][preds[i]])"
      ],
      "metadata": {
        "id": "41y2OuKaLyyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "oneList = [1]*len(cscoreMLP)"
      ],
      "metadata": {
        "id": "NhXmpX2uMBpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmsMLP = mean_squared_error(oneList,cscoreMLP, squared=False)"
      ],
      "metadata": {
        "id": "e-E9KVUHMFtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsMLP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOkVuTGgMI32",
        "outputId": "23be6f2c-d2e7-4b2c-c916-5489be09de4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23519540980543643"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "id": "qaUYuE3ZMMFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a96ab5-d716-4c59-da7c-e3426e92cc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ScT4P_hvaqBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}